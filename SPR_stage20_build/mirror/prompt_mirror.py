import streamlit as st
import pandas as pd
import jieba
import re
import json
import numpy as np
from wordcloud import WordCloud
from collections import Counter
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go

# é¡µé¢é…ç½®
st.set_page_config(page_title="SPR - ä½ çš„ Prompt ç”»åƒ", layout="wide", page_icon="ğŸ”®")

# --- å­—ä½“å¤„ç† (Mac ä¹±ç ç»ˆç»“ç‰ˆ - WordCloudç”¨) ---
import platform
def get_chinese_font():
    system = platform.system()
    if system == "Darwin": # Mac
        fonts = ["/System/Library/Fonts/PingFang.ttc", 
                 "/System/Library/Fonts/STHeiti Light.ttc",
                 "/System/Library/Fonts/Supplemental/Arial Unicode.ttf"]
        for f in fonts:
            try: 
                open(f)
                return f
            except: continue
    return None 

font_path = get_chinese_font()

# --- CSS ç¾åŒ– ---
st.markdown("""
<style>
    .main .block-container { padding-top: 2rem; }
    h1 { color: #2c3e50; }
    h3 { color: #34495e; font-size: 1.2rem; }
    .stMetric { background-color: #f8f9fa; padding: 15px; border-radius: 12px; border: 1px solid #eee; box-shadow: 0 2px 5px rgba(0,0,0,0.05); }
    .stDataFrame { border-radius: 10px; overflow: hidden; border: 1px solid #eee; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ”® SPR é•œåƒç‰ˆï¼šçœ‹è§ä½ çš„æ€ç»´ä¹ æƒ¯")

# ä¾§è¾¹æ ï¼šä¸Šä¼ 
with st.sidebar:
    st.header("ğŸ“¤ æ•°æ®å¯¼å…¥")
    st.info("è¯·ä½¿ç”¨ Chrome æ’ä»¶å¯¼å‡ºçš„ `my_prompts.json` æ–‡ä»¶")
    up = st.file_uploader("æ‹–å…¥æ–‡ä»¶", type=["json", "txt", "jsonl"])
    
    st.markdown("---")
    st.markdown("### éšç§è¯´æ˜")
    st.caption("æ‰€æœ‰è®¡ç®—å‡åœ¨æœ¬åœ°å®Œæˆï¼Œæ•°æ®ä¸ä¸Šä¼ äº‘ç«¯ã€‚")

# æ•°æ®åŠ è½½é€»è¾‘
lines = []
timestamps = []
sources = []

if up:
    try:
        content = up.read().decode('utf-8', errors='ignore')
        
        # 1. å°è¯•è§£ææ–°ç‰ˆæ’ä»¶ JSON [{ts, text, src}, ...]
        if up.name.endswith('.json'):
            try:
                data = json.loads(content)
                if isinstance(data, list) and len(data) > 0:
                    # æ£€æŸ¥æ˜¯ä¸æ˜¯æ’ä»¶æ ¼å¼
                    if 'text' in data[0]: 
                        for item in data:
                            lines.append(item.get('text', ''))
                            ts = item.get('ts', 0)
                            if ts > 0: timestamps.append(datetime.fromtimestamp(ts / 1000))
                            sources.append(item.get('src', 'unknown'))
                    # å…¼å®¹ ChatGPT å®˜æ–¹å¯¼å‡º
                    elif 'mapping' in data[0]:
                         for conv in data:
                            if 'mapping' in conv:
                                for k, v in conv['mapping'].items():
                                    if v['message'] and v['message']['author']['role'] == 'user':
                                        parts = v['message']['content']['parts']
                                        if parts: 
                                            lines.append(str(parts[0]))
                                            # å®˜æ–¹å¯¼å‡ºåŒ…å« create_time
                                            ct = v['message'].get('create_time')
                                            if ct: timestamps.append(datetime.fromtimestamp(ct))
            except json.JSONDecodeError:
                pass # å¯èƒ½æ˜¯å…¶ä»–æ ¼å¼

        # 2. å…¼å®¹æ—§ç‰ˆ TXT / JSONL
        if not lines: 
             if up.name.endswith('.jsonl'):
                for line in content.splitlines():
                    if line.strip():
                        try:
                            msg = json.loads(line)
                            if 'messages' in msg: lines.append(msg['messages'][0]['content'])
                        except: pass
             else:
                lines = [l.strip() for l in content.split('===SPLIT===') if l.strip()]
                if len(lines) < 2:
                     lines = [l.strip() for l in content.splitlines() if l.strip()]

    except Exception as e:
        st.error(f"è§£æå¤±è´¥: {e}")

if not lines:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®")
    st.stop()

# --- æ•°æ®é¢„å¤„ç† ---
df = pd.DataFrame({"prompt": lines})
df["len"] = df["prompt"].str.len()
if timestamps and len(timestamps) == len(lines):
    df["time"] = timestamps
    df["hour"] = df["time"].dt.hour
    df["date"] = df["time"].dt.date
    has_time = True
else:
    has_time = False

# åˆ†è¯
def get_words(text):
    return [w for w in jieba.lcut(text) if len(w) > 1 and re.match(r"[\u4e00-\u9fa5a-zA-Z]", w)]

all_text = " ".join(lines)
words = get_words(all_text)
word_counts = Counter(words)

# --- æ ¸å¿ƒæŒ‡æ ‡ ---
c1, c2, c3, c4 = st.columns(4)
c1.metric("ç´¯è®¡ Prompt", f"{len(df)} æ¡", delta=f"è¿‘7å¤© {len(df[df['time'] > pd.Timestamp.now() - pd.Timedelta(days=7)])} æ¡" if has_time else None)
c2.metric("å¹³å‡é•¿åº¦", f"{int(df['len'].mean())} å­—")
c3.metric("æ€»è¯æ±‡é‡", f"{len(word_counts)} ä¸ª")
most_common_word = word_counts.most_common(1)[0][0] if word_counts else "æ— "
c4.metric("æœ€çˆ±ç”¨çš„è¯", most_common_word)

st.divider()

# --- Tab å¸ƒå±€ ---
tab_visual, tab_data = st.tabs(["ğŸ“Š å¯è§†åŒ–åˆ†æ", "ğŸ“‹ åŸå§‹æ•°æ®è¡¨"])

with tab_visual:
    # --- ç¬¬ä¸€æ’ï¼šè¯äº‘ & äººæ ¼é›·è¾¾ ---
    col_cloud, col_radar = st.columns([1.5, 1])

    with col_cloud:
        st.subheader("â˜ï¸ ä½ çš„æ€ç»´è¯äº‘")
        
        wc = WordCloud(font_path=font_path, width=800, height=500, background_color="white", 
                       max_words=100, collocations=False).generate(" ".join(words))
        st.image(wc.to_array(), use_column_width=True)

    with col_radar:
        st.subheader("ğŸ•¸ï¸ Prompt äººæ ¼é›·è¾¾")
        
        # ç®€å•çš„å…³é”®è¯åˆ†ç±»å™¨
        categories = {
            "ğŸ’» ç¼–ç¨‹å¼€å‘": ["ä»£ç ", "code", "å‡½æ•°", "æŠ¥é”™", "bug", "python", "js", "react", "sql", "api", "å†™ä¸€ä¸ª", "å®ç°"],
            "ğŸ“ å†…å®¹åˆ›ä½œ": ["æ–‡æ¡ˆ", "æ–‡ç« ", "å‘¨æŠ¥", "æ€»ç»“", "æ‰©å†™", "æ¶¦è‰²", "å¤§çº²", "æ ‡é¢˜", "ç¿»è¯‘", "é‚®ä»¶"],
            "ğŸ§  é€»è¾‘åˆ†æ": ["åˆ†æ", "åŸå› ", "åŒºåˆ«", "æ¯”è¾ƒ", "è¯„ä»·", "ä¼˜ç¼ºç‚¹", "å»ºè®®", "æ–¹æ¡ˆ", "æ€ç»´å¯¼å›¾"],
            "ğŸ“ çŸ¥è¯†å­¦ä¹ ": ["è§£é‡Š", "ä»‹ç»", "æ˜¯ä»€ä¹ˆ", "å«ä¹‰", "åŸç†", "æ•™ç¨‹", "å­¦ä¹ ", "å¦‚ä½•"],
            "ğŸ¨ åˆ›æ„è„‘æš´": ["åˆ›æ„", "ç‚¹å­", "æ•…äº‹", "è®¾æƒ³", "å¦‚æœ", "ç”Ÿæˆ", "è®¾è®¡"]
        }
        
        scores = {k: 0 for k in categories}
        for w in words:
            w_lower = w.lower()
            for cat, keywords in categories.items():
                if w_lower in keywords:
                    scores[cat] += 1
        
        # å½’ä¸€åŒ–
        total_score = sum(scores.values()) or 1
        labels = list(scores.keys())
        values = [s/total_score for s in scores.values()]
        
        # Plotly é›·è¾¾å›¾
        fig_radar = px.line_polar(r=values, theta=labels, line_close=True)
        fig_radar.update_traces(fill='toself', line_color='#fb5607')
        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=False, range=[0, max(values)*1.1])),
            margin=dict(t=20, b=20, l=40, r=40),
            height=400
        )
        st.plotly_chart(fig_radar, use_container_width=True)

    st.divider()

    # --- ç¬¬äºŒæ’ï¼šæ—¶é—´åˆ†å¸ƒ & é•¿åº¦åˆ†å¸ƒ ---
    if has_time:
        st.subheader("ğŸ“… ä½ çš„æ´»è·ƒæ—¶æ®µ")
        c_time, c_len = st.columns([2, 1])
        
        with c_time:
            hour_counts = df['hour'].value_counts().sort_index()
            # è¡¥å…¨ 24 å°æ—¶
            for h in range(24):
                if h not in hour_counts: hour_counts[h] = 0
            hour_counts = hour_counts.sort_index()
            
            # Plotly æŸ±çŠ¶å›¾
            fig_time = px.bar(
                x=hour_counts.index, 
                y=hour_counts.values,
                labels={'x': 'å°æ—¶ (0-23)', 'y': 'Prompt æ•°é‡'},
                title="24å°æ—¶æ´»è·ƒåº¦çƒ­åŠ›"
            )
            fig_time.update_traces(marker_color='#3a86ff', hovertemplate="æ—¶é—´: %{x}ç‚¹<br>æ•°é‡: %{y}æ¡")
            fig_time.update_layout(xaxis=dict(tickmode='linear', dtick=2))
            st.plotly_chart(fig_time, use_container_width=True)
            
        with c_len:
             # Plotly ç›´æ–¹å›¾
             fig_len = px.histogram(
                 df, x="len", nbins=30,
                 title="Prompt é•¿åº¦åˆ†å¸ƒ",
                 labels={'len': 'å­—ç¬¦æ•°'},
                 color_discrete_sequence=['#ffbe0b']
             )
             fig_len.update_layout(showlegend=False)
             st.plotly_chart(fig_len, use_container_width=True)

    else:
        st.warning("âš ï¸ å½“å‰æ•°æ®ä¸åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œæ— æ³•æ˜¾ç¤ºæ´»è·ƒæ—¶æ®µåˆ†æã€‚è¯·ä½¿ç”¨æ–°ç‰ˆæ’ä»¶é‡æ–°å¯¼å‡º JSONã€‚")
        st.subheader("ğŸ“ Prompt é•¿åº¦åˆ†å¸ƒ")
        fig_len = px.histogram(df, x="len", nbins=30, color_discrete_sequence=['#ffbe0b'])
        st.plotly_chart(fig_len, use_container_width=True)

    # --- åº•éƒ¨ï¼šé«˜é¢‘è¯ç»„ (Bigrams) ---
    st.divider()
    st.subheader("ğŸ”— ä½ æœ€çˆ±ç”¨çš„çŸ­è¯­ (Top Phrases)")

    # ç®€å•çš„ Bigram å®ç°
    bigrams = []
    for line in lines:
        line_words = get_words(line)
        if len(line_words) >= 2:
            for i in range(len(line_words)-1):
                bigrams.append(f"{line_words[i]} {line_words[i+1]}")

    top_bigrams = Counter(bigrams).most_common(12)

    cols = st.columns(4)
    for i, (phrase, count) in enumerate(top_bigrams):
        with cols[i % 4]:
            st.button(f"{phrase} ({count})", key=f"bi_{i}", disabled=True)

with tab_data:
    st.subheader("ğŸ“‹ Prompt è¯¦æƒ…è¡¨")
    
    # æœç´¢æ¡†
    search_term = st.text_input("ğŸ” æœç´¢ Prompt å†…å®¹", "")
    
    # æ„å»ºå±•ç¤ºç”¨çš„ DataFrame
    display_df = df.copy()
    if has_time:
        display_df['time_str'] = display_df['time'].dt.strftime('%Y-%m-%d %H:%M')
        display_cols = ['time_str', 'prompt', 'len']
        col_config = {
            "time_str": st.column_config.TextColumn("æ—¶é—´", width="medium"),
            "prompt": st.column_config.TextColumn("å†…å®¹", width="large"),
            "len": st.column_config.NumberColumn("é•¿åº¦", width="small")
        }
    else:
        display_cols = ['prompt', 'len']
        col_config = {
            "prompt": st.column_config.TextColumn("å†…å®¹", width="large"),
            "len": st.column_config.NumberColumn("é•¿åº¦", width="small")
        }
    
    # è¿‡æ»¤
    if search_term:
        display_df = display_df[display_df['prompt'].str.contains(search_term, case=False)]
    
    st.dataframe(
        display_df[display_cols], 
        column_config=col_config,
        use_container_width=True,
        height=600,
        hide_index=True
    )
